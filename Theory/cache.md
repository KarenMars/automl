集成学习常用方法主要涉及三个方面，模型输入，模型选择，模型输出。下面主要介绍集成学习在模型输入方面的方法，与多模型的结合策略。

### 模型输入 
- Boosting
    - 初始时，给每一个训练样例赋予相同的权重，然后训练第一个基学习器并用其对训练集进行测试，对结果错误的测试样例提高权重；再利用调整后带有权重的训练集训练第二个基学习器，直到学习到一个好的学习器为止。
- Bagging 
    - 在包含$m$个样本的数据集中，**有放回**随机采样，经过$m$次得到包含$m$个样本的采样集。通过这样采样出$T$个含$m$个训练样本的采样集，然后基于采样集训练对应基学习器，在将基学习器结合。

- Boosting VS Bagging
    - 相同点
        - 都训练了$N$个基学习器
        - 都可以降低模型的方差，增加模型的泛化问题
    - 不同点
        - Bagging是并行的集成学习方法，Boosting是串行的集成学习方法
        - Bagging中基学习器是相互独立的，Boosting中，当前基学习器受到上一个基学习器的训练结果的影响
    - 何时使用
        - 减小Bias，使用Boosting
        - 解决Overfitting，使用Bagging
    - 缺点
        - 时间空间复杂度高


### 结合策略
- 分类问题，通常采用投票法；
- 回归问题，通常采用平均法；
